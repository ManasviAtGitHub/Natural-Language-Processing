{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot",
      "provenance": [],
      "authorship_tag": "ABX9TyN5i+G7zgH0cDpZtU/fo6RX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManasviAtGitHub/Natural-Language-Processing/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO3rXwmGyjjF",
        "outputId": "567c6bbe-f225-4557-aa23-9becd739e8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/NLP/datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCLsibIdzEki",
        "outputId": "0d251c84-5e90-4286-aab6-d67cb2de05f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoGPLEaEzErY",
        "outputId": "7d053fc6-351e-4b7d-f1f2-9d2441c73611"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 107 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=f1d79a56884111adef54a206578a243d4b306c34e6a793f28c0f9cfbcc06e437\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import numpy\n",
        "import tflearn\n",
        "import tensorflow\n",
        "import random\n",
        "import json\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUcCssQtzEwg",
        "outputId": "bf465237-fdaa-40e5-842c-643bcd3d685a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QyWQWRYzE4G",
        "outputId": "35eb6dc6-395b-4527-8d0f-1bd16f47c390"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = LancasterStemmer()"
      ],
      "metadata": {
        "id": "wr_237VTzoUQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "labels = []\n",
        "docs_x = []\n",
        "docs_y = []"
      ],
      "metadata": {
        "id": "ftZ20CE0z4Q8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"intents.json\") as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "nMP8Fdao0sBB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        wrds = nltk.word_tokenize(pattern)\n",
        "        words.extend(wrds)\n",
        "        docs_x.append(wrds)\n",
        "        docs_y.append(intent[\"tag\"])\n",
        "    print(f'docs_x: {docs_x}, docs_y: {docs_y}, Words: {words}')\n",
        "\n",
        "\n",
        "    if intent[\"tag\"] not in labels:\n",
        "        labels.append(intent[\"tag\"])\n",
        "    print(f'labels: {labels}')\n",
        "    \n",
        "words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
        "words = sorted(list(set(words)))\n",
        "labels = sorted(labels)\n",
        "training = []\n",
        "output = []\n",
        "out_empty = [0 for _ in range(len(labels))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nielJc_PzoX3",
        "outputId": "c581230b-f761-4bc9-9f83-56481d517032"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "docs_x: [['Hi'], ['How', 'are', 'you'], ['Is', 'anyone', 'there', '?'], ['Hello'], ['Good', 'day']], docs_y: ['greeting', 'greeting', 'greeting', 'greeting', 'greeting'], Words: ['Hi', 'How', 'are', 'you', 'Is', 'anyone', 'there', '?', 'Hello', 'Good', 'day']\n",
            "labels: ['greeting']\n",
            "docs_x: [['Hi'], ['How', 'are', 'you'], ['Is', 'anyone', 'there', '?'], ['Hello'], ['Good', 'day'], ['Bye'], ['See', 'you', 'later'], ['Goodbye']], docs_y: ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'goodbye'], Words: ['Hi', 'How', 'are', 'you', 'Is', 'anyone', 'there', '?', 'Hello', 'Good', 'day', 'Bye', 'See', 'you', 'later', 'Goodbye']\n",
            "labels: ['greeting', 'goodbye']\n",
            "docs_x: [['Hi'], ['How', 'are', 'you'], ['Is', 'anyone', 'there', '?'], ['Hello'], ['Good', 'day'], ['Bye'], ['See', 'you', 'later'], ['Goodbye'], ['Thanks'], ['Thank', 'you'], ['That', \"'s\", 'helpful']], docs_y: ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'goodbye', 'thanks', 'thanks', 'thanks'], Words: ['Hi', 'How', 'are', 'you', 'Is', 'anyone', 'there', '?', 'Hello', 'Good', 'day', 'Bye', 'See', 'you', 'later', 'Goodbye', 'Thanks', 'Thank', 'you', 'That', \"'s\", 'helpful']\n",
            "labels: ['greeting', 'goodbye', 'thanks']\n",
            "docs_x: [['Hi'], ['How', 'are', 'you'], ['Is', 'anyone', 'there', '?'], ['Hello'], ['Good', 'day'], ['Bye'], ['See', 'you', 'later'], ['Goodbye'], ['Thanks'], ['Thank', 'you'], ['That', \"'s\", 'helpful'], ['What', 'hours', 'are', 'you', 'open', '?'], ['What', 'are', 'your', 'hours', '?'], ['When', 'are', 'you', 'open', '?']], docs_y: ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'goodbye', 'thanks', 'thanks', 'thanks', 'hours', 'hours', 'hours'], Words: ['Hi', 'How', 'are', 'you', 'Is', 'anyone', 'there', '?', 'Hello', 'Good', 'day', 'Bye', 'See', 'you', 'later', 'Goodbye', 'Thanks', 'Thank', 'you', 'That', \"'s\", 'helpful', 'What', 'hours', 'are', 'you', 'open', '?', 'What', 'are', 'your', 'hours', '?', 'When', 'are', 'you', 'open', '?']\n",
            "labels: ['greeting', 'goodbye', 'thanks', 'hours']\n",
            "docs_x: [['Hi'], ['How', 'are', 'you'], ['Is', 'anyone', 'there', '?'], ['Hello'], ['Good', 'day'], ['Bye'], ['See', 'you', 'later'], ['Goodbye'], ['Thanks'], ['Thank', 'you'], ['That', \"'s\", 'helpful'], ['What', 'hours', 'are', 'you', 'open', '?'], ['What', 'are', 'your', 'hours', '?'], ['When', 'are', 'you', 'open', '?'], ['Do', 'you', 'take', 'credit', 'cards', '?'], ['Do', 'you', 'accept', 'Mastercard', '?'], ['Are', 'you', 'cash', 'only', '?']], docs_y: ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'goodbye', 'thanks', 'thanks', 'thanks', 'hours', 'hours', 'hours', 'payments', 'payments', 'payments'], Words: ['Hi', 'How', 'are', 'you', 'Is', 'anyone', 'there', '?', 'Hello', 'Good', 'day', 'Bye', 'See', 'you', 'later', 'Goodbye', 'Thanks', 'Thank', 'you', 'That', \"'s\", 'helpful', 'What', 'hours', 'are', 'you', 'open', '?', 'What', 'are', 'your', 'hours', '?', 'When', 'are', 'you', 'open', '?', 'Do', 'you', 'take', 'credit', 'cards', '?', 'Do', 'you', 'accept', 'Mastercard', '?', 'Are', 'you', 'cash', 'only', '?']\n",
            "labels: ['greeting', 'goodbye', 'thanks', 'hours', 'payments']\n",
            "docs_x: [['Hi'], ['How', 'are', 'you'], ['Is', 'anyone', 'there', '?'], ['Hello'], ['Good', 'day'], ['Bye'], ['See', 'you', 'later'], ['Goodbye'], ['Thanks'], ['Thank', 'you'], ['That', \"'s\", 'helpful'], ['What', 'hours', 'are', 'you', 'open', '?'], ['What', 'are', 'your', 'hours', '?'], ['When', 'are', 'you', 'open', '?'], ['Do', 'you', 'take', 'credit', 'cards', '?'], ['Do', 'you', 'accept', 'Mastercard', '?'], ['Are', 'you', 'cash', 'only', '?'], ['Are', 'you', 'open', 'today', '?'], ['When', 'do', 'you', 'open', 'today', '?'], ['What', 'are', 'your', 'hours', 'today', '?']], docs_y: ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'goodbye', 'thanks', 'thanks', 'thanks', 'hours', 'hours', 'hours', 'payments', 'payments', 'payments', 'opentoday', 'opentoday', 'opentoday'], Words: ['Hi', 'How', 'are', 'you', 'Is', 'anyone', 'there', '?', 'Hello', 'Good', 'day', 'Bye', 'See', 'you', 'later', 'Goodbye', 'Thanks', 'Thank', 'you', 'That', \"'s\", 'helpful', 'What', 'hours', 'are', 'you', 'open', '?', 'What', 'are', 'your', 'hours', '?', 'When', 'are', 'you', 'open', '?', 'Do', 'you', 'take', 'credit', 'cards', '?', 'Do', 'you', 'accept', 'Mastercard', '?', 'Are', 'you', 'cash', 'only', '?', 'Are', 'you', 'open', 'today', '?', 'When', 'do', 'you', 'open', 'today', '?', 'What', 'are', 'your', 'hours', 'today', '?']\n",
            "labels: ['greeting', 'goodbye', 'thanks', 'hours', 'payments', 'opentoday']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmvgspKA02sO",
        "outputId": "77aeb17f-f124-4c34-bb31-c4710a36cee7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"'s\",\n",
              " 'acceiv',\n",
              " 'anyon',\n",
              " 'ar',\n",
              " 'bye',\n",
              " 'card',\n",
              " 'cash',\n",
              " 'credit',\n",
              " 'day',\n",
              " 'do',\n",
              " 'good',\n",
              " 'goodby',\n",
              " 'hello',\n",
              " 'help',\n",
              " 'hi',\n",
              " 'hour',\n",
              " 'how',\n",
              " 'is',\n",
              " 'lat',\n",
              " 'mastercard',\n",
              " 'on',\n",
              " 'op',\n",
              " 'see',\n",
              " 'tak',\n",
              " 'thank',\n",
              " 'that',\n",
              " 'ther',\n",
              " 'today',\n",
              " 'what',\n",
              " 'when',\n",
              " 'yo',\n",
              " 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_empty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkRk7D295Cz8",
        "outputId": "1341119e-bdde-4227-d506-1179e7b108ae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, doc in enumerate(docs_x):\n",
        "  print(f'x : {x}, doc : {doc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoC9fSwZJ9tj",
        "outputId": "324f38aa-7d33-425b-b026-84308982d963"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x : 0, doc : ['Hi']\n",
            "x : 1, doc : ['How', 'are', 'you']\n",
            "x : 2, doc : ['Is', 'anyone', 'there', '?']\n",
            "x : 3, doc : ['Hello']\n",
            "x : 4, doc : ['Good', 'day']\n",
            "x : 5, doc : ['Bye']\n",
            "x : 6, doc : ['See', 'you', 'later']\n",
            "x : 7, doc : ['Goodbye']\n",
            "x : 8, doc : ['Thanks']\n",
            "x : 9, doc : ['Thank', 'you']\n",
            "x : 10, doc : ['That', \"'s\", 'helpful']\n",
            "x : 11, doc : ['What', 'hours', 'are', 'you', 'open', '?']\n",
            "x : 12, doc : ['What', 'are', 'your', 'hours', '?']\n",
            "x : 13, doc : ['When', 'are', 'you', 'open', '?']\n",
            "x : 14, doc : ['Do', 'you', 'take', 'credit', 'cards', '?']\n",
            "x : 15, doc : ['Do', 'you', 'accept', 'Mastercard', '?']\n",
            "x : 16, doc : ['Are', 'you', 'cash', 'only', '?']\n",
            "x : 17, doc : ['Are', 'you', 'open', 'today', '?']\n",
            "x : 18, doc : ['When', 'do', 'you', 'open', 'today', '?']\n",
            "x : 19, doc : ['What', 'are', 'your', 'hours', 'today', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orow = out_empty[:]"
      ],
      "metadata": {
        "id": "3yLMDwGELh3D"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(orow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CTK0GPOLk3k",
        "outputId": "151f2bb0-b6e9-467d-a35f-95c88e0f5586"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, doc in enumerate(docs_x):\n",
        "  bag = []\n",
        "  wrds = [stemmer.stem(w.lower()) for w in doc]\n",
        "  for w in words:\n",
        "      if w in wrds:\n",
        "          bag.append(1)\n",
        "      else:\n",
        "          bag.append(0)\n",
        "\n",
        "  output_row = out_empty[:]\n",
        "  output_row[labels.index(docs_y[x])] = 1\n",
        "  ##docs_y[x]\n",
        "  ## x = 0\n",
        "  ## docs_y[0] ==>> 'greeting'\n",
        "  ##labels.index('greetings')==>0\n",
        "  ## output_row [0] = 1\n",
        "\n",
        "  training.append(bag)\n",
        "  output.append(output_row)\n"
      ],
      "metadata": {
        "id": "vCi2vKOHzobJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training : {training[0]}, Output: {output[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuyG98_yOD3J",
        "outputId": "b9c7a403-b52d-4133-dfac-5ee4861dd358"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Output: [0, 1, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training = numpy.array(training)\n",
        "output = numpy.array(output)"
      ],
      "metadata": {
        "id": "9qPAHLwSzoey"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tensorflow.compat.v1.reset_default_graph()\n",
        "\n",
        "net = tflearn.input_data(shape=[None, len(training[0])])\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
        "net = tflearn.regression(net)"
      ],
      "metadata": {
        "id": "A8zP2_Kbzogc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tflearn.DNN(net)\n",
        "model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "# model.save(\"model.tflearn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97psCMJazokh",
        "outputId": "374dd0a5-c54f-44ed-fcf3-f4276feec1e1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 2999  | total loss: \u001b[1m\u001b[32m0.01452\u001b[0m\u001b[0m | time: 0.022s\n",
            "| Adam | epoch: 1000 | loss: 0.01452 - acc: 1.0000 -- iter: 16/20\n",
            "Training Step: 3000  | total loss: \u001b[1m\u001b[32m0.01429\u001b[0m\u001b[0m | time: 0.029s\n",
            "| Adam | epoch: 1000 | loss: 0.01429 - acc: 1.0000 -- iter: 20/20\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bag_of_words(s, words):\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "\n",
        "    s_words = nltk.word_tokenize(s)\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == se:\n",
        "                bag[i] = 1\n",
        "            \n",
        "    return numpy.array(bag)"
      ],
      "metadata": {
        "id": "6AihXovnzomF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat():\n",
        "    print(\"Start talking with the bot (type quit to stop)!\")\n",
        "    while True:\n",
        "        inp = input(\"You: \")\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        results = model.predict([bag_of_words(inp, words)])\n",
        "        print(results)\n",
        "        results_index = numpy.argmax(results)\n",
        "        print(results_index)\n",
        "        tag = labels[results_index]\n",
        "\n",
        "        for tg in data[\"intents\"]:\n",
        "            if tg['tag'] == tag:\n",
        "                responses = tg['responses']\n",
        "\n",
        "        print(random.choice(responses))"
      ],
      "metadata": {
        "id": "BwEBkrvdzon6"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU7THNau9jxb",
        "outputId": "7c52879b-60bf-49ce-dc95-b22e574896fc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start talking with the bot (type quit to stop)!\n",
            "You: hi, how are you ?\n",
            "[[1.7634567e-04 9.9905640e-01 3.2901691e-04 5.6016092e-06 1.3389500e-07\n",
            "  4.3241153e-04]]\n",
            "1\n",
            "Hi there, how can I help?\n",
            "You: Is your shop open\n",
            "[[0.02846025 0.44413322 0.44312474 0.06523647 0.00263152 0.01641374]]\n",
            "1\n",
            "Hello, thanks for visiting\n",
            "You: are you open \n",
            "[[0.02354181 0.06451001 0.8383112  0.06879287 0.00222847 0.0026156 ]]\n",
            "2\n",
            "Our hours are 9am-9pm every day\n",
            "You: hello good morning\n",
            "[[6.4024492e-04 9.9840564e-01 1.0208351e-04 1.6051857e-06 3.3580361e-07\n",
            "  8.5012463e-04]]\n",
            "1\n",
            "Good to see you again\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TwWH1xKj9pqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ymy9siSozovp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DjOIMhSizo08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bZWAMIAfzE7p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}